# LLM API Playground

複数のLLMプロバイダー（Anthropic, OpenAI, Google）のAIモデルとの対話を、統一されたインターフェースで実現する高機能なWebアプリケーションです。ファイルアップロード、モデルごとの動的なパラメータ設定、利用料金の追跡と上限設定など、実践的な機能を備えています。

## ✨ 機能概要

### 対応AIモデル

現在、以下のモデルをサポートしています。モデルの追加や設定は設定ファイルで容易に管理できます。

- **Anthropic Claude シリーズ:** Claude Sonnet 4
- **OpenAI GPT シリーズ:** GPT-5, GPT-5-mini, GPT-5-nano, GPT-4.1, O3, O4-mini
- **Google Gemini シリーズ:** Gemini 2.5 Pro, Gemini 2.5 Flash

### 主要機能

- **洗練されたUI/UX:**
  - **Markdown対応:** AIからの応答に含まれるMarkdownをリアルタイムで整形し、コードブロック、リスト、見出しなどを美しく表示します。
  - **入力欄の自動可変:** プロンプト入力欄は、入力内容に応じて高さが自動で調整されます。
  - **入力欄の固定表示:** チャット履歴をスクロールしても、プロンプト入力欄���常に画面下部に固定され、いつでもシームレスに入力が可能です。
  - **回答生成の中断:** AIが長い回答を生成している最中でも、ボタン一つで生成を即座に停止できます。
  - **Markdownのコピー:** AIの回答の右上に表示されるコピーボタンを押すことで、他のツールにそのまま貼り付けられるMarkdown形式の原文を簡単にコピーできます。

- **マルチプロバイダー対応:**
  - 複数のLLMをUIからシームレスに切り替えて利用可能。

- **動的なモデル設定:**
  - **通常モデル:** 「回答のスタイル（堅実/標準/創造的）」と「最大トークン数」を動的に設定可能。最大トークン数の上限は、各モデルの仕様に合わせて自動で調整されます。
  - **リーゾニングモデル:** 「リーゾニング精度（Low/Middle/High）」をプリセットから選択可能。
  - **GPT-5シリーズ:** 「リーゾニング精度（Minimal/Low/Medium/High）」と「回答の冗長性（Low/Medium/High）」を専用のパラメータで設定可能。冗長性は回答の詳細度を制御します。

- **Web検索連携:**
  - `o3` モデルでは、リアルタイムのWeb検索結果を基に回答を生成する機能が利用可能です。機密情報を含まない公開情報の検索・要約に活用できます。
  - **文脈理解力の強化:** Web検索利用時でも、過去の会話履歴全体を完全に参照します。これにより、「日本の総理大臣は？」→「その人の出身地は？」といった、文脈に依存する質問にも正確に応答できます。

- **ファイルアップロードと内容理解:**
  - 様々な形式のファイルをアップロードし、その内容をAIが深く理解した上で対話することが可能です。ファイルの種類に応じて、最適な方法で内容を解析します。
  - **対応ファイル:** 
  PDF, PNG, Word (.docx), Excel (.xlsx), テキスト (.txt), JSON (.json)
  - **画像ファイルの処理 (Vision機能):**
    - PNGなどの画像ファイルは、AIが持つ「視覚（Vision）」機能を使って、**画像に写っている内容そのもの**を直接認識します。風景、物体、グラフの形状、人物の表情などを理解し、より高度な対話が可能です。
  - **ドキュメントファイルの処理 (テキスト抽出):**
    - PDF, Word, Excelなどのドキュメントファイルは、Google Cloud Document AI (OCR) や各種ライブラリを用いて、ファイル内のテキスト情報を正確に抽出し、プロンプトに利用します。

- **利用料金トラッキングと上限設定:**
  - モデルごとのAPI利用料金をトークン数に基づいて自動で計算し、Firestoreに記録します。
  - 追跡は月単位で行われ、**月が替わると自動でリセットされます（先月分の履歴は破棄されます）**。
  - 月間の合計利用料金に加え、**日ごとの利用料金も記録・追跡**しています。
  - 特定のモデルに対して月間の利用料金上限を設定できます。
  - **UIへの警告表示:** モデル選択時、利用料金が上限の8割に達している場合は警告を表示し、��限に達したモデルは自動的に選択不可になります。

- **アップデート情報の確認:**
  - ヘッダーの「アップデート情報」ボタンから、いつでも最新の機能追加や修正に関するリリースノートを確認できます。

- **IPアドレスによるアクセス制限:**
  - 環境変数で指定されたIPアドレスからのアクセスのみを許可する、堅牢なセキュリティ機能を備えています。

## ⚙️ 設定と更新履歴の管理

### モデル設定のカスタマイズ

モデルの定義、料金、利用上限額などの設定は、すべて `src/config/models.json` ファイルで一元管理されています。新しいモデルの追加や既存モデルの設定変更は、このファイルを編集するだけで完了します。

### 更新履歴（リリースノート）の管理

アプリケーションの更新履歴は、プロジェクトのルートディレクトリにある `RELEASE_NOTES.md` ファイルで���理されています。機能追加やバグ修正を行った際は、このファイルにMarkdown形式で変更点を追記してください。記述された内容は、ヘッダーの「アップデート情報」から閲覧できます。

#### 追記フォーマットの例

```markdown
## YYYY-MM-DD

### ✨ 新機能

- 新しい機能の概要を記述します。

### 🐛 バグ修正

- 修正したバグの内容を記述します。
```

### `models.json` の構造

このJSONファイルは、4つの主要なキーで構成されています。

```json
{
  "modelGroups": [],
  "modelConfig": {},
  "monthlyLimitsUSD": {},
  "pricingPerMillionTokensUSD": {}
}
```

#### 1. `modelGroups`

UIのモデル選択ドロップダウンに表示されるモデルのリストとグループを定義します。

- `label`: プロバイダー名など、グループの見出しとして表示される文字列。
- `models`: グループに所属するモデルを定義するオブジェクト。
  - **キー (例: `"GPT-4.1"`)**: UIに表示されるモデル名。
  - **値 (例: `"gpt-4.1"`)**: アプリケーション内部で使われる一意のモデルID。

#### 2. `modelConfig`

各モデルの具体的な挙動と設定を定義します。キーには `modelGroups` で定義したモデルIDを���用します。

- `type`: モデルの種別を `"normal"`, `"reasoning"`, `"gpt5"` で指定します。これにより、UIに表示される設定項目が切り替わります。
- `maxTokens`: そのモデルが受け付ける最大のトークン数。UIのスライダーの最大値として使用されます。
- `service`: (任意) モデルが特別なサービスを必要とする場合に指定します。現在 `"gpt5"` のみサポートされています。

#### 3. `monthlyLimitsUSD`

特定のモデルに対する月間の利用料金（USD）の上限を設定します。ここにモデルIDと上限額を記述すると、自動で利用状況が監視されます。

- **キー**: 上限を設定したいモデルのID。
- **値**: 上限とする料金（数値）。

#### 4. `pricingPerMillionTokensUSD`

各モデルの100万トークンあたりの料金を定義します。従量課金の計算に利用されます。

- **キー**: 料金を設定するモデルのID。
- **値**: `input` (入力トークン単価) と `output` (出力トークン単価) を持つオブジェクト。

### 新しいモデルの追加手順

例として、新しい `GPT-X` という通常モデルを追加する場合の手順を以下に示します。

1.  **`modelGroups` に追加:**
    `"OpenAI"` グループに、��示名 `"GPT-X"` とモデルID `"gpt-x"` を追加します。
2.  **`modelConfig` に追加:**
    モデルID `"gpt-x"` の設定（`type` と `maxTokens`）を定義します。
3.  **`pricingPerMillionTokensUSD` に追加:**
    モデルID `"gpt-x"` の料金を定義します。
4.  **(任意) `monthlyLimitsUSD` に追加:**
    もしこのモデルに利用上限を設ける場合は、IDと上限額を追記します。

#### GPT-5シリーズモデルの追加と設定

GPT-5シリーズは、他のモデルとは異なる新しい`Responses API`を使用するため、特別な設定が必要です。

1.  **`modelGroups` に追加:** 通常モデルと同様に、表示名とモデルIDを追加します。
2.  **`modelConfig` に追加:**
    - `type` を `"gpt5"` に設定します。これにより、サイドバーにGPT-5専用の設定項目（リーゾニング精度、回答の冗長性）が表示されます。
    - `service` を `"gpt5"` に設定します。これにより、APIリクエストがGPT-5専用のサービス (`src/services/openai-gpt5.ts`) を経由するようになります。
    ```json
    "gpt-5-new": { "type": "gpt5", "maxTokens": 128000, "service": "gpt5" }
    ```
3.  **料金と上限設定:** `pricingPerMillionTokensUSD` と `monthlyLimitsUSD` にも忘れずに追加し���ください。

**現在の制約事項:**

- GPT-5シリーズが使用する`Responses API`は、現在 `maxTokens` と `temperature` パラメータをサポートしていません。そのため、UI上でこれらの設定項目は表示されず、デフォルト値が使用されます。

## ☁️ デプロイ

このアプリケーションは、Google Cloud Build を使ってCloud Runにデプロイされるように構成されています。リポジトリへのプッシュをトリガーとして、`cloudbuild.yaml` に定義されたパイプラインが自動的に実行されます。

1.  **Dockerイメージのビルド:** `Dockerfile` を基に、本番用のコンテナイメージがビルドされます。
2.  **Artifact Registryへのプッシュ:** ビルドされたイメージがArtifact Registryに保存されます。
3.  **Cloud Runへのデプロイ:** 最新のイメージを使って、Cloud Runサービスが更新されます。この際、Secret Managerから本番用の環境変数が安全にサービスに渡されます。